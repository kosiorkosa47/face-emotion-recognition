{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Inference with PyTorch Model\n",
    "\n",
    "This notebook demonstrates how to load a trained PyTorch model and predict emotions from a single image."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Define class labels\n",
    "class_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "# Load the trained model\n",
    "num_classes = 7\n",
    "model = models.mobilenet_v2(weights=None)\n",
    "model.classifier[1] = torch.nn.Linear(model.last_channel, num_classes)\n",
    "model.load_state_dict(torch.load('models/emotion_model_torch.pth', map_location='cpu'))\n",
    "model.eval()\n",
    "\n",
    "# Define image transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((96, 96)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load and preprocess an image\n",
    "img_path = 'your_image.jpg'  # Replace with your image path\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "input_tensor = transform(img).unsqueeze(0)\n",
    "\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "    pred = output.argmax(1).item()\n",
    "    print(f'Predicted class: {class_names[pred]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
